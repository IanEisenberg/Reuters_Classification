{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# references\n",
    "- text classification with word embeddings https://nadbordrozd.github.io/blog/2016/05/20/text-classification-with-word2vec/\n",
    "- preparing reuters https://miguelmalvarez.com/2015/03/20/classifying-reuters-21578-collection-with-python-representing-the-data/\n",
    "- classifying reuters with SVM https://miguelmalvarez.com/2016/11/07/classifying-reuters-21578-collection-with-python/\n",
    "- MUSE for multilingual word embeddings https://github.com/facebookresearch/MUSE\n",
    "- working with pretrained word vectors https://blog.manash.me/how-to-use-pre-trained-word-vectors-from-facebooks-fasttext-a71e6d55f27\n",
    "- term frequency-inverse document frequency (word weighting heuristic) https://en.wikipedia.org/wiki/Tf%E2%80%93idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data from nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import reuters\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "if not os.path.exists('wiki.multi.en.vec'):\n",
    "    urllib.urlretrieve (\"https://s3.amazonaws.com/arrival/embeddings/wiki.multi.en.vec\", \"wiki.multi.en.vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "embedding = KeyedVectors.load_word2vec_format('wiki.multi.en.vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import tf_idf, feature_values, tokenize\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_tokenizer = partial(tokenize, vocab=embedding.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data and train tf_IDF\n",
    "train_docs = []\n",
    "test_docs = []\n",
    "train_doc_ids = []\n",
    "test_doc_ids = []\n",
    "for doc in reuters.fileids():\n",
    "    if doc.startswith(\"train\"):\n",
    "        train_doc_ids.append(doc)\n",
    "        train_docs.append(reuters.raw(doc))\n",
    "    else:\n",
    "        test_doc_ids.append(doc)\n",
    "        test_docs.append(reuters.raw(doc))\n",
    "representer = tf_idf(train_docs, tokenize=vocab_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set max length to the 99th percentile length of all documents\n",
    "MAX_SEQ_LEN = int(np.percentile([len(i) for i in train_docs+test_docs], 90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert train docs to input\n",
    "# tokenize\n",
    "tokenized_inputs = [tokenize(doc, vocab=embedding.wv.vocab) for doc in train_docs]\n",
    "# convert to indices and pad\n",
    "def convert_to_index(doc, embedding):\n",
    "    return [embedding.index2word.index(w) for w in doc]\n",
    "seqs = [convert_to_index(doc, embedding) for doc in tokenized_inputs]\n",
    "inputs_pad = pad_sequences(seqs, maxlen=MAX_SEQ_LEN)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# keras impelemntation. Doesn't maintain the same association with the embeddig layer\n",
    "# convert to indices\n",
    "max_vocab_size = 200000\n",
    "input_tokenizer = Tokenizer(max_vocab_size)\n",
    "input_tokenizer.fit_on_texts(tokenized_inputs)\n",
    "input_vocab_size = len(input_tokenizer.word_index)\n",
    "# pad\n",
    "seqs = input_tokenizer.texts_to_sequences(tokenized_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "categories = reuters.categories()\n",
    "train_categories = [reuters.categories(doc) for doc in train_doc_ids]\n",
    "test_categories = [reuters.categories(doc) for doc in test_doc_ids]\n",
    "# transform into multilabel binarized representation\n",
    "mlb = MultiLabelBinarizer()\n",
    "train_labels = mlb.fit_transform([reuters.categories(doc_id)\n",
    "                                  for doc_id in train_doc_ids])\n",
    "test_labels = mlb.transform([reuters.categories(doc_id)\n",
    "                             for doc_id in test_doc_ids])\n",
    "# rare classes\n",
    "rare_cutoff = 6\n",
    "rare_classes = np.where(np.sum(train_labels,0)<rare_cutoff)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute class weights\n",
    "from sklearn.utils import class_weight\n",
    "category_list = np.hstack([np.where(doc>0)[0] for doc in train_labels])\n",
    "weighted_list = class_weight.compute_class_weight('balanced', np.unique(category_list), category_list)\n",
    "class_weights = {i: weighted_list[i] for i in range(len(mlb.classes_))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rebalance and remove low frequency categories\n",
    "single_class_labels = [(i,np.where(x==1)[0][0]) for i,x in enumerate(train_labels) if (np.sum(x)==1)]\n",
    "single_class_labels = [x for x in single_class_labels if x[1] not in rare_classes]\n",
    "x_subset = np.array([embedded_train_docs[i[0]] for i in single_class_labels])\n",
    "y_subset = np.array([i[1] for i in single_class_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reference https://link.springer.com/content/pdf/10.1007%2F978-3-642-41822-8_42.pdf\n",
    "# Managing Imbalanced Data Sets in Multi-label Problems: A Case Study with the SMOTE Algorithm\n",
    "# reweight\n",
    "# resample\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "smt = SMOTETomek()\n",
    "oversampler = RandomOverSampler()\n",
    "resampled_train_docs,resampled_train_labels=oversampler.fit_sample(x_subset,y_subset)\n",
    "# conver train_labels back to multilabel format\n",
    "onehot_encoder = OneHotEncoder(n_values=len(test_labels[0]), sparse=False)\n",
    "resampled_train_labels = onehot_encoder.fit_transform(np.expand_dims(resampled_train_labels,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train SVM on tf idf vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tfidf representation\n",
    "tfidf_train_docs=representer.transform(train_docs)\n",
    "tfidf_test_docs=representer.transform(test_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# inputs\n",
    "x_train = tfidf_train_docs\n",
    "x_test = tfidf_test_docs\n",
    "\n",
    "# Classifier\n",
    "classifier = OneVsRestClassifier(LinearSVC(random_state=42))\n",
    "classifier.fit(x_train, train_labels)\n",
    " \n",
    "predictions = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score,recall_score\n",
    " \n",
    "precision = precision_score(test_labels, predictions,\n",
    "                            average='micro')\n",
    "recall = recall_score(test_labels, predictions,\n",
    "                      average='micro')\n",
    "f1 = f1_score(test_labels, predictions, average='micro')\n",
    " \n",
    "print(\"Micro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\"\n",
    "        .format(precision, recall, f1))\n",
    " \n",
    "precision = precision_score(test_labels, predictions,\n",
    "                            average='macro')\n",
    "recall = recall_score(test_labels, predictions,\n",
    "                      average='macro')\n",
    "f1 = f1_score(test_labels, predictions, average='macro')\n",
    " \n",
    "print(\"Macro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\"\n",
    "        .format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trian SVM on word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(doc, representer, weighted=True):\n",
    "    tfidf_rep = representer.transform([doc])\n",
    "    if np.sum(tfidf_rep) == 0:\n",
    "        doc_embedding = np.zeros(embedding.vector_size)\n",
    "    else:\n",
    "        tfidf_words = representer.inverse_transform(tfidf_rep)[0]\n",
    "        weights = tfidf_rep.data\n",
    "        doc_word_embedding = np.vstack([embedding.get_vector(w) for w in tfidf_words])\n",
    "        if weighted:\n",
    "            doc_embedding = np.average(doc_word_embedding, axis=0, weights=weights)\n",
    "        else:\n",
    "            doc_embedding = np.sum(doc_word_embedding, axis=0)\n",
    "    return doc_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_train_docs = [get_embedding(doc, representer) for doc in train_docs]\n",
    "embedded_test_docs = [get_embedding(doc, representer) for doc in test_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# inputs\n",
    "x_train = embedded_train_docs\n",
    "x_test = embedded_test_docs\n",
    "\n",
    "# Classifier\n",
    "classifier = OneVsRestClassifier(LinearSVC(random_state=42))\n",
    "classifier.fit(x_train, train_labels)\n",
    " \n",
    "predictions = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score,recall_score\n",
    " \n",
    "precision = precision_score(test_labels, predictions,\n",
    "                            average='micro')\n",
    "recall = recall_score(test_labels, predictions,\n",
    "                      average='micro')\n",
    "f1 = f1_score(test_labels, predictions, average='micro')\n",
    " \n",
    "print(\"Micro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\"\n",
    "        .format(precision, recall, f1))\n",
    " \n",
    "precision = precision_score(test_labels, predictions,\n",
    "                            average='macro')\n",
    "recall = recall_score(test_labels, predictions,\n",
    "                      average='macro')\n",
    "f1 = f1_score(test_labels, predictions, average='macro')\n",
    " \n",
    "print(\"Macro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\"\n",
    "        .format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train on embedding with resampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# inputs\n",
    "x_train = resampled_train_docs\n",
    "x_test = embedded_test_docs\n",
    "\n",
    "# Classifier\n",
    "classifier = OneVsRestClassifier(LinearSVC(random_state=42))\n",
    "classifier.fit(x_train, resampled_train_labels)\n",
    " \n",
    "predictions = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score,recall_score\n",
    " \n",
    "precision = precision_score(test_labels, predictions,\n",
    "                            average='micro')\n",
    "recall = recall_score(test_labels, predictions,\n",
    "                      average='micro')\n",
    "f1 = f1_score(test_labels, predictions, average='micro')\n",
    " \n",
    "print(\"Micro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\"\n",
    "        .format(precision, recall, f1))\n",
    " \n",
    "precision = precision_score(test_labels, predictions,\n",
    "                            average='macro')\n",
    "recall = recall_score(test_labels, predictions,\n",
    "                      average='macro')\n",
    "f1 = f1_score(test_labels, predictions, average='macro')\n",
    " \n",
    "print(\"Macro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\"\n",
    "        .format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up keras classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv1D, Dense, Flatten, MaxPooling1D\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def custom_objective(y_true, y_pred):\n",
    "    '''Just another crossentropy'''\n",
    "    # Transform to logits\n",
    "    epsilon = tf.convert_to_tensor(K.common._EPSILON, y_pred.dtype.base_dtype)\n",
    "    y_pred = tf.clip_by_value(y_pred, epsilon, 1 - epsilon)\n",
    "    y_pred = tf.log(y_pred / (1 - y_pred))\n",
    "    loss = tf.nn.weighted_cross_entropy_with_logits(y_true, y_pred, weighted_list)\n",
    "    return tf.reduce_mean(loss, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "embedding_layer = embedding.get_keras_embedding()\n",
    "sequence_input = Input(shape=(MAX_SEQ_LEN,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(35)(x)  # global max pooling\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "preds = Dense(len(mlb.classes_), activation='sigmoid')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss=custom_objective,\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "\n",
    "# happy learning!\n",
    "history = model.fit(inputs_pad, train_labels,\n",
    "                    validation_split=0.1, batch_size=128, epochs=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pyplot inline\n",
    "import matplotlib.pyplot as plt\n",
    "i = 10\n",
    "predict = model.predict(inputs_pad[0:50])[i]\n",
    "plt.plot(predict)\n",
    "plt.plot(train_labels[i]*max(predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "num_examples = 50\n",
    "predicted = model.predict(inputs_pad[:num_examples])>.5\n",
    "y = train_labels[:num_examples]\n",
    "\n",
    "report = classification_report(y, predicted)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
