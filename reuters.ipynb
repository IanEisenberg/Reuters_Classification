{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# references\n",
    "- text classification with word embeddings https://nadbordrozd.github.io/blog/2016/05/20/text-classification-with-word2vec/\n",
    "- preparing reuters https://miguelmalvarez.com/2015/03/20/classifying-reuters-21578-collection-with-python-representing-the-data/\n",
    "- classifying reuters with SVM https://miguelmalvarez.com/2016/11/07/classifying-reuters-21578-collection-with-python/\n",
    "- MUSE for multilingual word embeddings https://github.com/facebookresearch/MUSE\n",
    "- working with pretrained word vectors https://blog.manash.me/how-to-use-pre-trained-word-vectors-from-facebooks-fasttext-a71e6d55f27\n",
    "- term frequency-inverse document frequency (word weighting heuristic) https://en.wikipedia.org/wiki/Tf%E2%80%93idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data from nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import reuters\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "if not os.path.exists('wiki.multi.en.vec'):\n",
    "    urllib.urlretrieve (\"https://s3.amazonaws.com/arrival/embeddings/wiki.multi.en.vec\", \"wiki.multi.en.vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "embedding = KeyedVectors.load_word2vec_format('wiki.multi.en.vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import tf_idf, feature_values, tokenize\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_tokenizer = partial(tokenize, vocab=embedding.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data and train tf_IDF\n",
    "train_docs = []\n",
    "test_docs = []\n",
    "train_doc_ids = []\n",
    "test_doc_ids = []\n",
    "for doc in reuters.fileids():\n",
    "    if doc.startswith(\"train\"):\n",
    "        train_doc_ids.append(doc)\n",
    "        train_docs.append(reuters.raw(doc))\n",
    "    else:\n",
    "        test_doc_ids.append(doc)\n",
    "        test_docs.append(reuters.raw(doc))\n",
    "representer = tf_idf(train_docs, tokenize=vocab_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set max length to the 99th percentile length of all documents\n",
    "MAX_SEQ_LEN = int(np.percentile([len(i) for i in train_docs+test_docs], 90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# convert train docs to input\n",
    "# tokenize\n",
    "tokenized_inputs = [tokenize(doc, vocab=embedding.wv.vocab) for doc in train_docs]\n",
    "# convert to indices and pad\n",
    "def convert_to_index(doc, embedding):\n",
    "    return [embedding.index2word.index(w) for w in doc]\n",
    "seqs = [convert_to_index(doc, embedding) for doc in tokenized_inputs]\n",
    "inputs_pad = pad_sequences(seqs, maxlen=MAX_SEQ_LEN)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# keras impelemntation. Doesn't maintain the same association with the embeddig layer\n",
    "# convert to indices\n",
    "max_vocab_size = 200000\n",
    "input_tokenizer = Tokenizer(max_vocab_size)\n",
    "input_tokenizer.fit_on_texts(tokenized_inputs)\n",
    "input_vocab_size = len(input_tokenizer.word_index)\n",
    "# pad\n",
    "seqs = input_tokenizer.texts_to_sequences(tokenized_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tfidf representation\n",
    "tfidf_train_docs=representer.transform(train_docs)\n",
    "tfidf_test_docs=representer.transform(test_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(doc, representer, weighted=True):\n",
    "    tfidf_rep = representer.transform([doc])\n",
    "    if np.sum(tfidf_rep) == 0:\n",
    "        doc_embedding = np.zeros(embedding.vector_size)\n",
    "    else:\n",
    "        tfidf_words = representer.inverse_transform(tfidf_rep)[0]\n",
    "        weights = tfidf_rep.data\n",
    "        doc_word_embedding = np.vstack([embedding.get_vector(w) for w in tfidf_words])\n",
    "        if weighted:\n",
    "            doc_embedding = np.average(doc_word_embedding, axis=0, weights=weights)\n",
    "        else:\n",
    "            doc_embedding = np.sum(doc_word_embedding, axis=0)\n",
    "    return doc_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_train_docs = [get_embedding(doc, representer) for doc in train_docs]\n",
    "embedded_test_docs = [get_embedding(doc, representer) for doc in test_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "categories = reuters.categories()\n",
    "train_categories = [reuters.categories(doc) for doc in train_doc_ids]\n",
    "test_categories = [reuters.categories(doc) for doc in test_doc_ids]\n",
    "# transform into multilabel binarized representation\n",
    "mlb = MultiLabelBinarizer()\n",
    "train_labels = mlb.fit_transform([reuters.categories(doc_id)\n",
    "                                  for doc_id in train_doc_ids])\n",
    "test_labels = mlb.transform([reuters.categories(doc_id)\n",
    "                             for doc_id in test_doc_ids])\n",
    "# rare classes\n",
    "rare_cutoff = 6\n",
    "rare_classes = np.where(np.sum(train_labels,0)<rare_cutoff)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute class weights\n",
    "from sklearn.utils import class_weight\n",
    "category_list = np.hstack([np.where(doc>0)[0] for doc in train_labels])\n",
    "weighted_list = class_weight.compute_class_weight('balanced', np.unique(category_list), category_list)\n",
    "class_weights = {i: weighted_list[i] for i in range(len(mlb.classes_))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rebalance dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rebalance and remove low frequency categories\n",
    "single_class_labels = [(i,np.where(x==1)[0][0]) for i,x in enumerate(train_labels) if (np.sum(x)==1)]\n",
    "single_class_labels = [x for x in single_class_labels if x[1] not in rare_classes]\n",
    "x_subset = np.array([embedded_train_docs[i[0]] for i in single_class_labels])\n",
    "y_subset = np.array([i[1] for i in single_class_labels])\n",
    "\n",
    "# reference https://link.springer.com/content/pdf/10.1007%2F978-3-642-41822-8_42.pdf\n",
    "# Managing Imbalanced Data Sets in Multi-label Problems: A Case Study with the SMOTE Algorithm\n",
    "# reweight\n",
    "# resample\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "oversampler = RandomOverSampler()\n",
    "resampled_train_docs,resampled_train_labels=oversampler.fit_sample(x_subset,y_subset)\n",
    "# conver train_labels back to multilabel format\n",
    "onehot_encoder = OneHotEncoder(n_values=len(test_labels[0]), sparse=False)\n",
    "resampled_train_labels = onehot_encoder.fit_transform(np.expand_dims(resampled_train_labels,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot data characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train SVM on tf idf vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# inputs\n",
    "x_train = tfidf_train_docs\n",
    "x_test = tfidf_test_docs\n",
    "\n",
    "# Classifier\n",
    "classifier = OneVsRestClassifier(LinearSVC(random_state=42))\n",
    "classifier.fit(x_train, train_labels)\n",
    " \n",
    "predictions = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro-average quality numbers\n",
      "Precision: 0.9441, Recall: 0.7978, F1-measure: 0.8648\n",
      "Macro-average quality numbers\n",
      "Precision: 0.6088, Recall: 0.3622, F1-measure: 0.4314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score,recall_score\n",
    " \n",
    "precision = precision_score(test_labels, predictions,\n",
    "                            average='micro')\n",
    "recall = recall_score(test_labels, predictions,\n",
    "                      average='micro')\n",
    "f1 = f1_score(test_labels, predictions, average='micro')\n",
    " \n",
    "print(\"Micro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\"\n",
    "        .format(precision, recall, f1))\n",
    " \n",
    "precision = precision_score(test_labels, predictions,\n",
    "                            average='macro')\n",
    "recall = recall_score(test_labels, predictions,\n",
    "                      average='macro')\n",
    "f1 = f1_score(test_labels, predictions, average='macro')\n",
    " \n",
    "print(\"Macro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\"\n",
    "        .format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trian SVM on word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# inputs\n",
    "x_train = embedded_train_docs\n",
    "x_test = embedded_test_docs\n",
    "\n",
    "# Classifier\n",
    "classifier = OneVsRestClassifier(LinearSVC(random_state=42))\n",
    "classifier.fit(x_train, train_labels)\n",
    " \n",
    "predictions = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro-average quality numbers\n",
      "Precision: 0.9428, Recall: 0.5812, F1-measure: 0.7191\n",
      "Macro-average quality numbers\n",
      "Precision: 0.2688, Recall: 0.0798, F1-measure: 0.1072\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score,recall_score\n",
    " \n",
    "precision = precision_score(test_labels, predictions,\n",
    "                            average='micro')\n",
    "recall = recall_score(test_labels, predictions,\n",
    "                      average='micro')\n",
    "f1 = f1_score(test_labels, predictions, average='micro')\n",
    " \n",
    "print(\"Micro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\"\n",
    "        .format(precision, recall, f1))\n",
    " \n",
    "precision = precision_score(test_labels, predictions,\n",
    "                            average='macro')\n",
    "recall = recall_score(test_labels, predictions,\n",
    "                      average='macro')\n",
    "f1 = f1_score(test_labels, predictions, average='macro')\n",
    " \n",
    "print(\"Macro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\"\n",
    "        .format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train on embedding with resampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 2 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 5 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 7 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 8 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 11 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 12 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 14 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 16 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 18 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 27 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 28 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 30 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 33 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 37 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 42 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 48 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 51 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 52 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 53 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 56 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 57 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 58 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 60 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 61 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 62 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 63 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 64 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 65 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 68 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 70 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 73 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 74 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 75 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 76 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 79 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 80 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 81 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 86 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 88 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-5cf67d0864b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresampled_train_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/sklearn/multiclass.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0mindptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m                 \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_predict_binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m                 \u001b[0mindptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/sklearn/multiclass.pyc\u001b[0m in \u001b[0;36m_predict_binary\u001b[0;34m(estimator, X)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;31m# probabilities of the positive class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/sklearn/multiclass.pyc\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         return np.repeat([np.hstack([1 - self.y_, self.y_])],\n\u001b[0;32m--> 130\u001b[0;31m                          X.shape[0], axis=0)\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# inputs\n",
    "x_train = resampled_train_docs\n",
    "x_test = embedded_test_docs\n",
    "\n",
    "# Classifier\n",
    "classifier = OneVsRestClassifier(LinearSVC(random_state=42))\n",
    "classifier.fit(x_train, resampled_train_labels)\n",
    " \n",
    "predictions = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score,recall_score\n",
    " \n",
    "precision = precision_score(test_labels, predictions,\n",
    "                            average='micro')\n",
    "recall = recall_score(test_labels, predictions,\n",
    "                      average='micro')\n",
    "f1 = f1_score(test_labels, predictions, average='micro')\n",
    " \n",
    "print(\"Micro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\"\n",
    "        .format(precision, recall, f1))\n",
    " \n",
    "precision = precision_score(test_labels, predictions,\n",
    "                            average='macro')\n",
    "recall = recall_score(test_labels, predictions,\n",
    "                      average='macro')\n",
    "f1 = f1_score(test_labels, predictions, average='macro')\n",
    " \n",
    "print(\"Macro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\"\n",
    "        .format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up keras classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv1D, Dense, Flatten, MaxPooling1D\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def custom_objective(y_true, y_pred, prob):\n",
    "    '''Just another crossentropy'''\n",
    "    # Transform to logits\n",
    "    epsilon = tf.convert_to_tensor(K.common._EPSILON, y_pred.dtype.base_dtype)\n",
    "    y_pred = tf.clip_by_value(y_pred, epsilon, 1 - epsilon)\n",
    "    y_pred = tf.log(y_pred / (1 - y_pred))\n",
    "    loss = tf.nn.weighted_cross_entropy_with_logits(y_true, y_pred, prob)\n",
    "    return tf.reduce_mean(loss, axis=-1)\n",
    "\n",
    "loss = partial(custom_objective, prob=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /media/Data/Ian/miniconda/envs/tf2.7/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "Train on 6992 samples, validate on 777 samples\n",
      "Epoch 1/2\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "embedding_layer = embedding.get_keras_embedding()\n",
    "sequence_input = Input(shape=(MAX_SEQ_LEN,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(35)(x)  # global max pooling\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "preds = Dense(len(mlb.classes_), activation='sigmoid')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss=loss,\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "\n",
    "# happy learning!\n",
    "history = model.fit(inputs_pad, train_labels,\n",
    "                    validation_split=0.1, batch_size=128, epochs=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pyplot inline\n",
    "import matplotlib.pyplot as plt\n",
    "i = 10\n",
    "predict = model.predict(inputs_pad[0:50])[i]\n",
    "plt.plot(predict)\n",
    "plt.plot(train_labels[i]*max(predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "num_examples = 50\n",
    "predicted = model.predict(inputs_pad[:num_examples])>.5\n",
    "y = train_labels[:num_examples]\n",
    "\n",
    "report = classification_report(y, predicted)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
